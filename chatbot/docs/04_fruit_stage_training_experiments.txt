4단계: 열매 단계 – 학습 및 실험
===============================

이 단계에서는 설계한 모델을 실제로 훈련시키고 성능을 최적화하는 방법을 학습합니다.

4.1 학습 과정 이해
-----------------

**순전파 (Forward Pass)**
1. 입력 데이터가 모델을 통과하며 예측값 생성
2. 각 층에서 가중치와 입력의 연산 수행
3. 활성화 함수 적용으로 비선형 변환
4. 최종 출력층에서 예측 결과 도출

**손실 계산 (Loss Calculation)**
- **손실 함수**: 예측값과 정답 간의 차이 측정
- **분류용**: CrossEntropy Loss (다중 클래스), Binary CrossEntropy (이진 분류)
- **회귀용**: Mean Squared Error (MSE), Mean Absolute Error (MAE)

**역전파 (Backpropagation)**
1. 손실에서부터 거꾸로 그래디언트 계산
2. 각 가중치가 손실에 미치는 영향 파악
3. 체인 룰을 이용한 미분 연산

**가중치 업데이트 (Weight Update)**
- **옵티마이저**: 가중치 업데이트 알고리즘
  - **SGD**: 가장 기본적인 방법
  - **Adam**: 적응적 학습률, 가장 널리 사용
  - **RMSprop**: 학습률 자동 조정
- **학습률(Learning Rate)**: 가중치 변경 폭 조절

4.2 파라미터 설정 실습
---------------------

**핵심 하이퍼파라미터**

**1) 학습률 (Learning Rate)**
- 범위: 0.001 ~ 0.1
- 너무 큰 값: 발산, 학습 불안정
- 너무 작은 값: 느린 학습, 지역 최솟값 갇힘
- 권장: 0.001에서 시작, 필요시 조정

**2) 배치 크기 (Batch Size)**
- 범위: 16, 32, 64, 128
- 큰 배치: 안정적 학습, 많은 메모리 필요
- 작은 배치: 노이즈 있는 학습, 메모리 효율적
- 권장: GPU 메모리에 맞춰 32 또는 64

**3) 에포크 (Epochs)**
- 전체 데이터셋을 몇 번 반복 학습할지
- 범위: 10 ~ 200
- 너무 많으면: 과적합 위험
- 너무 적으면: 학습 부족

**4) 조기 종료 (Early Stopping)**
- 검증 손실이 개선되지 않으면 학습 중단
- 과적합 방지 및 시간 절약
- 인내심(Patience): 몇 에포크 동안 개선 없으면 중단

4.3 학습 실행 & 시각화
---------------------

**학습 과정 모니터링**

**1) 손실 그래프**
- 훈련 손실 vs 검증 손실 비교
- 과적합 징후: 훈련 손실은 감소, 검증 손실은 증가
- 학습 부족: 두 손실 모두 높은 상태로 수렴

**2) 정확도 그래프**
- 훈련 정확도 vs 검증 정확도 추이
- 목표: 두 정확도가 함께 상승하며 수렴

**3) 학습률 스케줄링**
- **고정**: 처음부터 끝까지 동일한 학습률
- **감소**: 특정 에포크마다 학습률 감소
- **코사인 어닐링**: 코사인 함수 형태로 감소

**실시간 시각화 도구**
- **TensorBoard**: 실시간 그래프 및 로그 확인
- **Wandb**: 클라우드 기반 실험 추적
- **Matplotlib**: 기본적인 그래프 생성

4.4 모델 성능 향상 실험
----------------------

**성능 평가 지표**

**분류 문제**
- **정확도(Accuracy)**: 전체 중 맞춘 비율
- **정밀도(Precision)**: 예측한 양성 중 실제 양성 비율
- **재현율(Recall)**: 실제 양성 중 예측한 양성 비율
- **F1-Score**: 정밀도와 재현율의 조화 평균
- **혼동 행렬**: 클래스별 예측 결과 매트릭스

**모델 개선 전략**

**1) 데이터 관점**
- 더 많은 데이터 수집
- 데이터 증강 기법 추가
- 클래스 불균형 해결 (오버샘플링, 언더샘플링)

**2) 모델 구조 관점**
- 레이어 깊이 조정
- 필터 수 증가/감소
- 드롭아웃 비율 조정
- 배치 정규화 추가

**3) 학습 전략 관점**
- 학습률 스케줄링
- 옵티마이저 변경
- 손실 함수 변경
- 전이 학습 활용

**실험 관리**

**1) 실험 기록**
- 모델 구조, 하이퍼파라미터, 성능 지표 기록
- 재현 가능하도록 시드 설정
- 코드 버전 관리

**2) A/B 테스트**
- 한 번에 하나의 변수만 변경
- 기준 모델과 개선 모델 비교
- 통계적 유의성 확인

**3) 교차 검증**
- K-Fold 교차 검증으로 안정적 성능 측정
- 여러 번 실험하여 평균 성능 계산

**고급 최적화 기법**

**1) 앙상블**
- 여러 모델의 예측을 결합
- 보팅, 배깅, 부스팅 기법 활용

**2) 하이퍼파라미터 튜닝**
- 그리드 서치: 모든 조합 시도
- 랜덤 서치: 무작위 조합 시도
- 베이지안 최적화: 효율적 탐색

**3) 전이 학습**
- 사전 훈련된 모델 활용
- 특성 추출기 + 새로운 분류기
- 적은 데이터로도 높은 성능 달성

실험 체크리스트
--------------
- [ ] 기준 모델 성능 측정 완료
- [ ] 하이퍼파라미터 실험 계획 수립
- [ ] 실험 결과 기록 시스템 구축
- [ ] 과적합 모니터링 설정
- [ ] 최종 모델 선택 기준 명확화
- [ ] 모델 저장 및 버전 관리 준비

성공적인 AI 프로젝트 완성
------------------------
이 단계를 완료하면 실제 문제를 해결할 수 있는 AI 모델을 개발할 수 있습니다. 지속적인 실험과 개선을 통해 더 나은 성능을 달성해보세요.