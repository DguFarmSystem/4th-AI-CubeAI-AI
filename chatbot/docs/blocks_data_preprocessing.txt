데이터 전처리 블록 상세 가이드
===============================

이 문서는 블록 코딩 시스템에서 사용되는 데이터 전처리 블록들의 상세 설명입니다.

데이터 선택 블록 (data_selection)
===============================

**목적**: 훈련용 및 테스트용 데이터셋을 선택하고 설정합니다.

**파라미터**
- `dataset`: 훈련용 CSV 파일 선택
- `is_test`: 테스트 데이터 사용 여부 (true/false)
- `testdataset`: 테스트용 CSV 파일 선택 (is_test가 true일 때)

**언제 사용하나요?**
- 프로젝트 시작 시 데이터셋을 불러올 때
- 훈련용과 테스트용 데이터를 분리해서 사용하고 싶을 때
- 별도의 검증 데이터셋이 있을 때

**사용 방법**
```python
# 훈련 데이터만 사용하는 경우
dataset = "train_data.csv"
is_test = False

# 훈련/테스트 데이터 모두 사용하는 경우  
dataset = "train_data.csv"
is_test = True
testdataset = "test_data.csv"
```

빈 데이터 삭제 블록 (drop_na)
============================

**목적**: 데이터셋에서 결측치(NaN)가 포함된 행을 제거합니다.

**파라미터**: 없음 (자동 처리)

**언제 사용하나요?**
- 데이터에 빈 값이나 누락된 정보가 있을 때
- 불완전한 데이터로 인한 학습 오류를 방지하고 싶을 때
- 데이터 품질을 개선하고 싶을 때

**어떻게 작동하나요?**
```python
train_df = train_df.dropna()  # 학습 데이터에서 NaN 포함 행 제거
test_df  = test_df.dropna()   # 테스트 데이터에서 NaN 포함 행 제거
```

**주의사항**
- 데이터 양이 크게 줄어들 수 있습니다
- 결측치가 많다면 대체 방법(평균값 채우기 등) 고려
- 학습 데이터와 테스트 데이터 모두에 적용해야 합니다

**실제 효과**
- Before: 1000개 행 → After: 850개 행 (결측치 15% 제거)
- 모델 학습 시 오류 방지
- 데이터 일관성 확보

픽셀 값 정규화 블록 (normalize)
==============================

**목적**: 이미지 픽셀 값을 일정한 범위로 조정하여 학습 효율을 높입니다.

**파라미터**
- `method`: 정규화 방법 선택 (0-1 선택하기)

**언제 사용하나요?**
- 이미지 데이터를 다룰 때 (필수)
- 모델 학습 속도를 높이고 싶을 때
- 그래디언트 폭발/소실 문제를 방지하고 싶을 때

**방법 1: 0-1 정규화**
```python
X_train = X_train / 255.0  # 0~255 → 0~1
X_test  = X_test  / 255.0
```
- **언제 사용**: 대부분의 경우, 일반적인 CNN 모델
- **장점**: 직관적이고 이해하기 쉬움
- **적합한 활성화 함수**: ReLU, Sigmoid

**방법 2: -1~1 정규화**
```python
X_train = X_train / 127.5 - 1.0  # 0~255 → -1~1
X_test  = X_test  / 127.5 - 1.0
```
- **언제 사용**: GAN, 일부 고급 모델
- **장점**: 대칭적 분포, 0 중심
- **적합한 활성화 함수**: Tanh

**왜 정규화가 필요한가요?**
- **학습 안정성**: 큰 값으로 인한 그래디언트 폭발 방지
- **수렴 속도**: 더 빠른 학습 가능
- **가중치 초기화**: 초기 가중치와 잘 맞음

잘못된 라벨 삭제 블록 (drop_bad_labels)
=====================================

**목적**: 지정된 범위를 벗어난 잘못된 라벨을 가진 데이터를 제거합니다.

**파라미터**
- `min_label`: 허용하는 최소 라벨 값 (기본값: 0)
- `max_label`: 허용하는 최대 라벨 값 (기본값: 9)

**언제 사용하나요?**
- 라벨이 잘못 입력된 데이터가 있을 때
- 특정 클래스만 학습하고 싶을 때
- 데이터 수집 과정에서 오류가 발생했을 때

**어떻게 작동하나요?**
```python
# 0~9 범위의 라벨만 유지 (MNIST 숫자 분류 예시)
train_df = train_df[(train_df['label'] >= 0) & (train_df['label'] <= 9)]
test_df  = test_df[(test_df['label'] >= 0) & (test_df['label'] <= 9)]
```

**실제 사례**
- MNIST 데이터에서 -1이나 10 같은 잘못된 라벨 제거
- 이미지 분류에서 존재하지 않는 클래스 제거

데이터 나누기 블록 (split_data)
=============================

**목적**: 전체 데이터를 학습용과 테스트용으로 분할합니다.

**파라미터**
- `train_ratio`: 학습용 데이터 비율 (a%, 기본값: 80)
- `is_test`: 테스트 CSV 지정 여부 (true/false)
- 미지정 시 테스트 비율 = 100-a (%)

**언제 사용하나요?**
- 하나의 데이터셋을 학습/테스트로 나누고 싶을 때
- 별도의 테스트 파일이 없을 때
- 데이터를 무작위로 섞어서 분할하고 싶을 때

**사용 방법**
```python
# 80:20 비율로 분할
train_ratio = 80
is_test = False

# 별도 테스트 파일 사용
is_test = True
```

이미지 크기 변경 블록 (resize)
=============================

**목적**: 모든 이미지를 동일한 크기로 변환합니다.

**파라미터**
- `width`: 목표 가로 크기 (기본값: 28)
- `height`: 목표 세로 크기 (기본값: 28)

**언제 사용하나요?**
- 이미지 크기가 다양할 때 (필수)
- 메모리 사용량을 줄이고 싶을 때
- 모델 입력 크기에 맞추고 싶을 때

**어떻게 작동하나요?**
```python
# 모든 이미지를 28×28 크기로 변환
from PIL import Image
resized_image = image.resize((28, 28))
```

**크기 선택 가이드**
- **28×28**: MNIST, 간단한 실습용
- **64×64**: 빠른 실험, 프로토타입
- **224×224**: 일반적인 이미지 분류 (ImageNet 표준)
- **512×512**: 고해상도, 정밀한 분류

**주의사항**
- 너무 작으면: 중요한 정보 손실
- 너무 크면: 메모리 및 계산 부담 증가

데이터 증강 블록 (augment)
=========================

**목적**: 기존 데이터를 변형하여 데이터셋 크기를 늘리고 일반화 성능을 향상시킵니다.

**파라미터 및 방법 선택**
- `method`: 증강 방법 선택 (rotate, hflip, vflip, translate)

**증강 기법별 설명**

**1) 회전 (rotate)**
- **파라미터**: 회전 각도(°)
- **효과**: 객체가 기울어져 있어도 인식 가능
- **주의**: 너무 많이 회전하면 원본과 달라짐

**2) 좌우 반전 (hflip)**
- **파라미터**: 없음
- **효과**: 객체의 방향에 무관하게 인식
- **주의**: 텍스트나 비대칭 객체는 부적절

**3) 상하 반전 (vflip)**
- **파라미터**: 없음
- **효과**: 상하 방향 변화에 강건
- **주의**: 자연스럽지 않은 경우가 많음

**4) 이동 (translate)**
- **파라미터**: 이동 픽셀 수
- **효과**: 객체 위치 변화에 강건
- **적용**: 객체가 이미지 중앙에 없어도 인식

**언제 사용하나요?**
- 데이터가 부족할 때
- 과적합을 방지하고 싶을 때
- 모델의 일반화 성능을 높이고 싶을 때

**사용 예시**
```python
# 회전 + 좌우반전 조합
augmented_data = rotate(image, angle=15) + horizontal_flip(image, prob=0.5)
```

입력/라벨 분리 블록 (split_xy)
=============================

**목적**: DataFrame을 특성(X)과 라벨(y)로 분리하고 텐서 형태로 변환합니다.

**파라미터**: 없음 (자동 처리)

**언제 사용하나요?**
- 모델 훈련 직전 단계
- 데이터를 모델이 이해할 수 있는 형태로 변환할 때

**어떻게 작동하나요?**
```python
# DataFrame에서 특성과 라벨 분리
X_train = train_df.drop(columns=['label']).values
y_train = train_df['label'].values
X_test  = test_df.drop(columns=['label']).values
y_test  = test_df['label'].values

# 텐서 형태로 변환 (PyTorch/TensorFlow 호환)
X_train = torch.FloatTensor(X_train)
y_train = torch.LongTensor(y_train)
```

**결과**
- **X_train/X_test**: 이미지 데이터 (특성)
- **y_train/y_test**: 정답 라벨
- 자동으로 X_train, y_train, X_test, y_test 생성 및 Tensor 변환

전처리 블록 사용 순서
===================

**권장 순서**
1. **데이터 선택** → 훈련/테스트 데이터셋 선택
2. **빈 데이터 삭제** → 결측치 제거 (자동 처리)
3. **잘못된 라벨 삭제** → 이상 라벨 제거 (min_label, max_label)
4. **데이터 나누기** → 학습/테스트 분할 (train_ratio, is_test)
5. **입력/라벨 분리** → X, y 분리 및 Tensor 변환 (자동 처리)
6. **이미지 크기 변경** → 크기 통일 (width, height)
7. **이미지 증강** → 데이터셋 확장 (rotate, hflip, vflip, translate)
8. **픽셀 값 정규화** → 값 범위 조정 (0-1 선택하기)

**블록 조합 예시**
```
[데이터 선택] → [빈 데이터 삭제] → [잘못된 라벨 삭제] → [데이터 나누기] → [입력/라벨 분리] → [크기 변경(28×28)] → [증강(rotate)] → [정규화(0-1)]
```

각 블록의 효과를 확인하면서 단계별로 진행하는 것이 중요합니다!